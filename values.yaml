# Default values for hlf-kube.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

hyperledgerVersion: 1.4.5

# see the Raft sample in the README for how to enable TLS
tlsEnabled: false
ca.ingress.enabled: true
ingress.enabled: true
# use actual domain names like peer0.atlantis.com instead of internal service names
# this should be set to true for TLS
useActualDomains: false

# adds additional DNS entries to /etc/hosts files
# see https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/#adding-additional-entries-with-hostaliases
# this value should be provided if either tlsEnabled or useActualDomains is set to true
# see the Raft sample in the README for how to use this
hostAliases: []

# common persistence settings
persistence:
  storageClass: default

backup:
  # initiate backup procedure?
  enabled: false
restore:
  # initiate restore procedure?
  enabled: false

# common settings for CouchDB and CA ingresses
ingress:
  # all ingress subdomains will be created under this domain
  parentDomain:
  annotations:
    kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: letsencrypt-prod

# peer settings. applies to all peers
peer:
  logLevel: info
  # launch peer pods? setting to false is useful for collecting host aliases and fast restart afterwards
  launchPods: true
  chaincode:
    # attach chaincode's stdout to peer?
    attachStdout: true
    logging:
      level:  info
      shim:   info
  persistence:
    enabled: false
    size: 16Gi
  ingress:
    enabled: false
    annotations:
      # this should match the ingressClass when peer ingress controller is created
      kubernetes.io/ingress.class: "hlf-peer"
  externalService:
    # expose peers to outer world with LoadBalancer service type?
    enabled: false
    annotations:
  # if enabled, podAntiAffinity is used to spread the peer pods in the same organization among nodes
  # normally no need to disable this
  antiAffinity:
    enabled: true
    # is antiAffinity preferred or required?
    strict: false
  backup: 
    # take backup of peers during backup procedure?
    enabled: true
  restore: 
    # restore peers data from backup during restore procedure?
    enabled: true
  operations:
    enabled: false
    listenAddress: 0.0.0.0:9443
    servicePort: 9443
    tls:
      enabled: false
  metrics:
    enabled: false
    provider: prometheus
    
# CouchDB settings. applies to all CouchDB's
couchdb:
  version: 0.4.15
  userName: 
  password:
  persistence:
    enabled: false
    size: 16Gi
  ingress:
    enabled: false
  backup: 
    # take backup of CouchDB's during backup procedure?
    enabled: true
  restore: 
    # restore CouchDB's data from backup during restore procedure?
    enabled: true

# Orderer settings. applies to all Orderer pods
orderer:
  # should be greater than 1 only if kafka orderer is used
  replicas: 1
  logLevel: info
  # launch orderer pods? setting to false is useful for collecting host aliases and fast restart afterwards
  launchPods: true
  persistence:
    enabled: false
    size: 16Gi
  # when enabled, internal communication among Raft orderers are done at a different port
  # useful when you dont want to enable TLS globally (i.e for transparent load balancing)
  # has no effect if orderer type is not etcdraft
  cluster:
    enabled: false
    # raft cluster communication port. should be in synch with consenters in configtx.yaml
    port: 7059
  ingress:
    enabled: false
    annotations:
      # this should match the ingressClass when orderer ingress controller is created
      kubernetes.io/ingress.class: "hlf-orderer"
  externalService:
    # expose orderers to outer world with LoadBalancer service type?
    enabled: false
    annotations:
  # if enabled, podAntiAffinity is used to spread the orderer pods in the same organization among nodes
  # normally no need to disable this
  antiAffinity:
    enabled: true
    # is antiAffinity preferred or required?
    strict: false
  backup: 
    # take backup of orderers during backup procedure?
    enabled: true
  restore: 
    # restore orderers data from backup during restore procedure?
    enabled: true
  operations:
    enabled: false
    listenAddress: 0.0.0.0:8443
    servicePort: 8443
    tls: 
      enabled: false
  metrics:
    enabled: false
    provider: prometheus    

# CA (Certificate Authority) settings. applies to all CA's
ca:
  userName: admin
  password: adminpw
  logLevel: info
  ingress:
    enabled: false

# chaincode settings
chaincode:
  # fill in this array with chaincode names to limit the chaincode ConfigMap only to these ones
  include: []


# kafka settings
hlf-kafka:
  # install kafka?
  enabled: false

  # number of Kafka brokers, should be at least 4
  # https://hyperledger-fabric.readthedocs.io/en/release-1.4/kafka.html
  replicas: 4
  podManagementPolicy: Parallel

  # TODO storage classs?
  persistence:
    enabled: false
    storageClass: default
    size: 16Gi

  configurationOverrides: 
    "default.replication.factor": 4  # given a 4 node Kafka cluster
    "unclean.leader.election.enable": false
    "min.insync.replicas": 3  # to permit one Kafka replica to go offline
    "message.max.bytes": "103809024"  # 99 * 1024 * 1024 B
    "replica.fetch.max.bytes": "103809024"  # 99 * 1024 * 1024 B
    "log.retention.ms": -1  # Since we need to keep logs indefinitely for the HL Fabric Orderer

  zookeeper:
    # should be 3, 5, or 7
    replicaCount: 3

    persistence:
      enabled: false
      storageClass: default
      size: 16Gi
    
    
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry and imagePullSecrets
##
# global:
#   imageRegistry: myRegistryName
#   imagePullSecrets:
#     - myRegistryKeySecretName
#   storageClass: myStorageClass

## Bitnami Odoo image version
## ref: https://hub.docker.com/r/bitnami/odoo/tags/
##
image:
  registry: docker.io
  repository: hyperledger/explorer
  tag: latest
  ## Specify a imagePullPolicy
  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  ##
  pullPolicy: IfNotPresent
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ##
  # pullSecrets:
  #   - myRegistryKeySecretName

## String to partially override odoo.fullname template (will maintain the release name)
##
# nameOverride:

## String to fully override odoo.fullname template
##
# fullnameOverride:

## User of the application
## ref: https://github.com/bitnami/bitnami-docker-odoo#configuration
##
##odooUsername: user@example.com

## Admin email
## ref: https://github.com/bitnami/bitnami-docker-odoo#configuration
##
##odooEmail: user@example.com

## Application password
## Defaults to a random 10-character alphanumeric string if not set
## ref: https://github.com/bitnami/bitnami-docker-odoo#configuration
##
# odooPassword:

## SMTP mail delivery configuration
## ref: https://github.com/bitnami/bitnami-docker-odoo/#smtp-configuration
# smtpHost:
# smtpPort:
# smtpUser:
# smtpPassword:
# smtpProtocol:

externalDatabase:
## All of these values are only used when postgresql.enabled is set to false
  ## Database host
  host: odoo-postgresql

  ## non-root Username for Odoo database
  user: hppoc

  ## Database password
  password: password

  ## Database port number
  port: 5432

##
## PostgreSQL chart configuration
##
## https://github.com/bitnami/charts/blob/master/bitnami/postgresql/values.yaml
##
postgresql:
  enabled: true
  ## PostgreSQL password
  ## ref: https://hub.docker.com/_/postgres/
  ##
  postgresqlUsername: hppoc
  postgresqlPassword: password

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    enabled: true
    ## If you want to reuse an existing claim, you can pass the name of the PVC using
    ## the existingClaim variable
    ##
    # existingClaim: your-claim

    ## postgresql data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass: "-"
    accessMode: ReadWriteOnce
    size: 8Gi

## Kubernetes svc configuration
## For minikube, set this to NodePort, elsewhere use LoadBalancer
##
## Use serviceLoadBalancerIP to request a specific static IP,
## otherwise leave blank
##
service:
  ## Kubernetes svc type
  ## For minikube, set this to NodePort, elsewhere use LoadBalancer
  ##
  type: LoadBalancer
  ## Use serviceLoadBalancerIP to request a specific static IP,
  ## otherwise leave blank
  ##
  # loadBalancerIP:
  # HTTP Port
  port: 80
  ## Use nodePort to requets some specific port when usin NodePort
  ##
  nodePort: ""

  ## Enable client source IP preservation
  ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
  ##
  externalTrafficPolicy: Cluster

## Configure the ingress resource that allows you to access the
## Odoo installation. Set up the URL
## ref: http://kubernetes.io/docs/user-guide/ingress/
##
ingress:
  ## Set to true to enable ingress record generation
  enabled: false

  ## The list of hostnames to be covered with this ingress record.
  ## Most likely this will be just one host, but in the event more hosts are needed, this is an array
  hosts:
  - name: odoo.local
    path: /

    ## Set this to true in order to enable TLS on the ingress record
    ## A side effect of this will be that the backend odoo service will be connected at port 443
    tls: false

    ## If TLS is set to true, you must declare what secret will store the key/certificate for TLS
    tlsSecret: odoo.local-tls

  ## Set this to true in order to add the corresponding annotations for cert-manager
  certManager: false
  ## Ingress annotations done as key:value pairs
  ## For a full list of possible ingress annotations, please see
  ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
  ##
  ## If tls is set to true, annotation ingress.kubernetes.io/secure-backends: "true" will automatically be set
  ## If certManager is set to true, annotation kubernetes.io/tls-acme: "true" will automatically be set
  annotations:
  #  kubernetes.io/ingress.class: nginx
  #  kubernetes.io/tls-acme: true

  secrets:
  ## If you're providing your own certificates, please use this to add the certificates as secrets
  ## key and certificate should start with -----BEGIN CERTIFICATE----- or
  ## -----BEGIN RSA PRIVATE KEY-----
  ##
  ## name should line up with a tlsSecret set further up
  ## If you're using cert-manager, this is unneeded, as it will create the secret for you if it is not set
  ##
  ## It is also possible to create and manage the certificates outside of this helm chart
  ## Please see README.md for more information
  # - name: odoo.local-tls
  #   key:
  #   certificate:

## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  enabled: true
  ## odoo data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  accessMode: ReadWriteOnce
  size: 8Gi

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 512Mi
    cpu: 300m

## Configure extra options for liveness and readiness probes
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes)
livenessProbe:
  enabled: false
  initialDelaySeconds: 600
  periodSeconds: 30
  timeoutSeconds: 5
  failureThreshold: 6
  successThreshold: 1
readinessProbe:
  enabled: false
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 6
  successThreshold: 1

## Affinity for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}
